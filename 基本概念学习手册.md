## [特征图和感受野](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter05_CNN/5.1_conv-layer?id=_516-特征图和感受野)

二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素$x$的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做$x$的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为$2 \times 2$的输出记为$Y$，并考虑一个更深的卷积神经网络：将$Y$与另一个形状为$2 \times 2$的核数组做互相关运算，输出单个元素$z$。那么，$z$在$Y$上的感受野包括$Y$的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。

## 循环神经网络（Recurrent Neural Networks)

RNN 是一种可以预测未来（在某种程度上）的神经网络，可以用来分析时间序列数据（比如分析股价，预测买入点和卖出点）。在自动驾驶中，可以预测路线来避免事故。更一般的，它可以任意序列长度作为输入，而不是我们之前模型使用的固定序列长度。例如 RNN 可以将句子、文档、语音作为输入，进行自动翻译、情感分析、语音转文字。此外，RNN 还用于作曲（谷歌Magenta项目作出的the one）、作文、图片自动生成标题。

## skip / residual connections

> 为了应对梯度消失挑战, ResNet 的设计理念是允许低层的原始信息直接传到后续的高层, 让高层专注残差的学习, 避免模型的退化.

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200327153848581.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NodWNodXM=,size_16,color_FFFFFF,t_70)

我们可以使用一个非线性变化函数来描述一个网络的输入输出，即输入为X，输出为F(x)，F通常包括了卷积，激活等操作。当我们强行将一个输入添加到函数的输出的时候，虽然我们仍然可以用G(x)来描述输入输出的关系，但是这个G(x)却可以明确的拆分为F(x)和X的线性叠加

## 卷积神经网络 CNN

### FCN (fully connected network layer)

拉伸输入 为1-D vector 保证输出大小为想要的结果

### Convolution Layer

> preserve spatial structure

filter (卷积核) size F\*F\*3 

input size: N\*N\*3 

output size:  (N-F)/stride +1 

**padding**: 补充数 保持输入输出尺寸一致

**parameter number**： 卷积核的大小 之和+ padding的数量

### Pooling Layer (down-sampling)

```python
'''
1 MaxPool
torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
'''

```

>kernel_size- 窗口大小
>stride- 步长。默认值是kernel_size
>padding - 补0数
>dilation– 控制窗口中元素步幅的参数
>return_indices - 如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助
>ceil_mode - 如果等于True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取的操作



### 因果卷积 (causal Convolutions)

https://blog.csdn.net/u013195114/article/details/105565696

对于因果卷积，存在的一个问题是需要很多层或者很大的filter来增加卷积的感受野
为了解决这个问题，出现了**扩展卷积（dilated）**

### 空洞/扩张卷积（dilated convolution）

https://www.zhihu.com/question/54149221
对图像做卷积再pooling，降低图像尺寸的同时增大感受野，但是由于图像分割预测是pixel-wise的输出，所以要将pooling后较小的图像尺寸upsampling到原始的图像尺寸进行预测（upsampling一般采用deconv反卷积操作，deconv可参见知乎答案[如何理解深度学习中的deconvolution networks？](https://www.zhihu.com/question/43609045/answer/132235276)），之前的pooling操作使得每个pixel预测都能看到较大感受野信息。因此图像分割FCN中有两个关键，一个是pooling减小图像尺寸增大感受野，另一个是upsampling扩大图像尺寸。在先减小再增大尺寸的过程中，肯定有一些信息损失掉了，那么能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？答案就是dilated conv 
dilated的好处是不做pooling损失信息的情况下，加大了感受野，让每个卷积输出都包含较大范围的信息。在图像需要全局信息或者语音文本需要较长的sequence信息依赖的问题中，都能很好的应用dilated conv，比如图像分割[3]、语音合成WaveNet[2]、机器翻译ByteNet[1]中

### 反卷积|转置卷积 (deconvolution|transposed convolution)
转置卷积被用到的地方还挺多，比如做图片的unsupervised learning, ZF-Net的卷积网络可视, FCN (full convolution network )的upsampling和GAN网络的图片生成

> 比较直观一点的理解是，在CNN中，通过convolution过后的feature map通常会一层层缩小，而反卷积则相反，它会对feature产生“放大”的作用 

## GAN (Generative Adversarial Net) 生成对抗网络

two models: an adversarial model and a discriminative model

https://zhuanlan.zhihu.com/p/26499443

这里的两个网络一个是生成网络，一个是判别网络

![img](https://pic4.zhimg.com/80/v2-51892332cee9db5811d011ee36225377_720w.jpg)

生成网络通过regression为目的进行生成虚假数据与真实数据进行混合，混合后一起传给判别网络进行判断

在训练过程中，D会接收真数据和G产生的假数据，它的任务是判断图片是属于真数据的还是假数据的。对于最后输出的结果，可以同时对两方的参数进行调优。如果D判断正确，那就需要调整G的参数从而使得生成的假数据更为逼真；如果D判断错误，则需调节D的参数，避免下次类似判断出错。训练会一直持续到两者进入到一个均衡和谐的状态。

训练后的产物是一个质量较高的自动生成器和一个判断能力较强强的分类器。前者可以用于机器创作（自动画出“猫”“狗”），而后者则可以用来机器分类（自动判断“猫”“狗”）。