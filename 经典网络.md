# CS 231n

## AlexNet

**First layer** : Conv 1 : 96 个 $11\times 11$ filter stride 4  

for dataset 'ImageNet' input_size = $227\times 227\times 3(rgb)$  

1. what is the output volume size?

> $(227-11)/4 +1 = 55$  
> so the output size is $55\times 55 \times 96$ 

2.  what is the total number of parameters in this layer?
> $11\times 11 \times  96 \times 3 = 35k$
> In which, first $11 \times 11$ means size of filter, 96 means the number of 96, 3 means the depth (rgb).

**Second layer** : pooling $3 \times 3$ applied at stride 2
1. what is the output volume size?
>  $(55-3)/2 +1 = 27 $   
>  so the output size is $27\times 27 \times 96 $   
2. parameters?
> None!

3. Why no parameters in pooling layer?
> we just to find the max/average value from the receptive field

**some details** 

- ReLU
- Norm Layer
- dropout = 0.5
- batch size =128
- SGD momentum = 0.9
- lr = 1e-2

## VGG

smaller filters, deeper networks  

8 layers(AlexNet) $\rightarrow$ 16~19 layers(VGG16Net)  

> only   
>
> $3\times 3$ conv, stride 1, pad 1  
>
> $2\times 2$ MaxPool stride 2

1. Why use smaller filters? (3\*3 conv)
> stack of three $ 3\times 3$ filters has the same effective receptive field as one which is $ 7 \times 7$ conv layer  
> And with the same receptive field, three $3\times 3$ filters have fewer parameters than $7\times 7$, deeper constructions means we have more chances to add some nonlinear operation​s
2. what is the effective receptive field of three $3\times 3 $ conv layer?
> 7 $\times$ 7, you can draw an image to show it

## GoogleNet (Inception)

- No FC layers! (full connection)
- Only 5 million parameters (12 x less than AlexNet)
- Efficient Inception module

  <img src="D:\WPS Cloud Files\notes\imgs\Inception1.jpg" alt="Inception1" style="zoom: 67%;" />

1. How to keep the output size equal?
> by zero-padding 
2. Inception function?
> Inception使用split-transform-merge策略把multi-scale filter生成的不同感受野的特征融合到一起，有利于识别不同尺度的对象
3. How to solve the 'deeper and deeper'?
> adding $1\times 1$ filter conv, 能减少运算量

Inception v2和v3是在同一篇文章中提出来的。相比Inception v1，结构上的改变主要有两点：1）用堆叠的小kernel size（3\*3）的卷积来替代Inception v1中的大kernel size（5\*5）卷积；2）引入了空间分离卷积（Factorized Convolution）来进一步降低网络的复杂度。

<img src="D:\WPS Cloud Files\notes\imgs\Inception2.jpg" alt="Inception2" style="zoom:67%;" />

v4 融合了ResNet 结构

## ResNet (residual connection)

VGG中，卷积网络达到了19层，在GoogLeNet中，网络史无前例的达到了22层。那么，网络的精度会随着网络的层数增多而增多吗？在深度学习中，网络层数增多一般会伴着下面几个问题

1. 计算资源的消耗

2. 模型容易过拟合

3. 梯度消失/梯度爆炸问题的产生

残差网络应运而生  

![residual_block](D:\WPS Cloud Files\notes\imgs\residual_block.jpg)

图中的Weight在卷积网络中是指卷积操作，addition是指单位加操作

作者给出的解释是，网络的一层通常可以看做 ![[公式]](https://www.zhihu.com/equation?tex=y%3DH%28x%29) , 而残差网络的一个残差块可以表示为 ![[公式]](https://www.zhihu.com/equation?tex=H%28x%29%3DF%28x%29%2Bx) ，也就是 ![[公式]](https://www.zhihu.com/equation?tex=F%28x%29+%3D+H%28x%29-x) ，在单位映射中， ![[公式]](https://www.zhihu.com/equation?tex=y%3Dx) 便是观测值，而 ![[公式]](https://www.zhihu.com/equation?tex=H%28x%29) 是预测值，所以 ![[公式]](https://www.zhihu.com/equation?tex=F%28x%29) 便对应着残差，因此叫做残差网络

- 'googlenet' + 'resnet' $\rightarrow$ ResNext


## Faster R-CNN (Region Proposal Network)

## YOLO/SSD

# Human Pose Estimation

## Convolutional Pose Machines

## Hourglass

## Open Pose

## SimpleBaseline

## Cascaded Pyramid Network (CPN)

## DensePose

## HR Net

# Transformer

## self-attention

## SE Net

## Why attention is All you need

## ViT (Vison Transformer)

## DETR 

##  





